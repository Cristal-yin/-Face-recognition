# Pytorch动态神经网络

### 前言

+ 人工神经网络 VS 生物神经网络

  并不相等

  就像飞机模仿鸟而不等于鸟

+ 什么是神经网络

  数学模型或计算机模型

  + 基于传统统计学建模的工具

  + 神经网络系统由多层神经元构成，由输出层输出

  + 隐藏层可以有多层，但是一般都是一层，负责传入信息的加工处理

    就像人类的感知信息一样，要进行多层加工

  + 电脑只能用数字来表示图片或者语音等

    计算机判断一张图片也是通过数字

  + 激活函数

    通过激活函数对传入的信息进行激活，被激活的信息是计算机最为重视的信息，对输出结果最有价值的信息，每一个类别的图片对应的信息不同

+ 神经网络， 梯度下降

  优化问题

  (求导，求微分)

  + cost Function

    经常用平方差来做

    但是如果曲线这样，只能得到局部最优解，但是一般的问题用局部最优解也可以解决

    ![](images/0201.png)

    

+ 神经网络的黑盒不黑

  输入端-->黑盒-->输出端

    

## 第一章

+ 为什么使用pytorch

+ 安装

+ Numpy和torch对比

+ Variable变量

+ 激励函数(非线性的函数)

  为了结果不能用线性方程解决的问题

  使用特别多的隐藏层的激励函数选择慎重

  默认首选 ：CNN relu

  RNN tanh relu

## 第三章

+ 优化器

  SGD Momentum  RMSprop Adam



## CNN 卷积神经网络

## 流行的CNN结构

输入的图片 ->  卷积层 ->  池化层 -> 卷积层 -> 池化层 ->两层全连接的神经层 ->分类器

## RNN

+ **LSTM循环神经网络**

  LSTM和普通的RNN相比，多出了三个控制器(输入控制，输出控制，忘记控制) 

  LSTM RNN 内部  多了一个 控制全局的记忆

  对于空寂机制，LSTM就像延缓记忆衰退的良药，可以带来更好的结果

+ **分类RNN**

  MNIST数据集RNN

  黑色的地方的值都是0，白色的地方值大于0

  同样，我们除了训练数据，还给一些测试数据，测试看看它有没有训练好

## 自编码Autoencoder

自编码是一种神经网络的形式， 

+ encoder编码器，编码器能得到原数据的精髓，然后我们只需要再创建一个小的神经网络学习这个精髓的数据，不仅减少了神经网络的负担，而且同样能达到很好的效果

+ 一个通过自编码整理出来的数据， 能够从原数据中总结出每种类型数据的特征，如果把这些特征类型都放在一张二维的图片上，每种类型都已经被很好的用元数据的精髓区分来，

+ Decoder解码器

  解码器就是在训练的时候要将精髓信息解压成原始信息，那么这就提供了一个解压器的作用，甚至我们可以认为是一个生成器

+ MNIST数据集

  压缩解压看是否和原来的数据一样，因此是非监督学习

  